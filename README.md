## mitm_twitter_search

Small mitmproxy addon to intercept X/Twitter SearchTimeline GraphQL requests.

Features
- Detects requests with path like `/i/api/graphql/<id>/SearchTimeline` on hosts that end with `x.com`.
- Logs a short summary to mitmproxy's console.
- Appends request and response records to `mitm_twitter_search_intercepts.jsonl` (JSON Lines format).
- Extracts a compact set of Tweet + user fields and stores them into a local SQLite DB `mitm_twitter_search.db`.

Usage (Windows / PowerShell)

1. Install mitmproxy:

```powershell
python -m pip install --upgrade pip
python -m pip install mitmproxy
```

2. Run mitmproxy headless (mitmdump) with the addon:

```powershell
mitmdump -s .\mitm_twitter_search.py
```

3. Use your browser or application with mitmproxy running (or configure your system to use the mitmproxy instance). Intercepted requests/responses will be logged and appended to `mitm_twitter_search_intercepts.jsonl`.

4. The addon parses SearchTimeline GraphQL responses for TimelineTweet items and persists a reduced object containing only the fields you asked for into a local SQLite DB (`mitm_twitter_search.db`).

Example extracted fields stored in sqlite (per tweet): the same compact set of fields shown earlier are saved as structured columns in `mitm_twitter_search.db` (one row per tweet).

Notes
- The script is intentionally focused on detection and logging. You can modify it to alter requests/responses (e.g., to inject headers or change payloads) — tell me what you'd like and I can extend it.
- Be mindful of legal and privacy implications when intercepting network traffic.

Next steps
- If you want, I can add filtering options, write unit tests, or provide helper scripts to parse `mitm_twitter_search_intercepts.jsonl`.
 - If you want, I can add filtering options, write unit tests, or provide helper scripts to parse the extracted file `mitm_twitter_search_extracted.jsonl`.

(Removed local test helper and sample response — extraction is intended to be used live with mitmproxy.)

SQLite storage
--------------
The addon now saves extracted tweet objects into a local SQLite database at the repo root named `mitm_twitter_search.db` instead of the extracted JSONL file.

Quick usage:

```powershell
# inspect DB with sqlite3 CLI
sqlite3 mitm_twitter_search.db "PRAGMA table_info(tweets);"
sqlite3 mitm_twitter_search.db "SELECT id_str, entryId, screen_name, created_at, ts FROM tweets ORDER BY rowid DESC LIMIT 10;"
```
Note: mitmproxy logs insertion events to its console (ctx.log.info). Look for messages like:

	INFO: Inserted tweet id_str=1994387910242734583 into DB /path/to/mitm_twitter_search.db

If you don't see insert messages, check that the response body contains JSON and that the tweet object includes id_str.

The DB schema includes a `tweets` table with columns for each of the fields you requested (name, screen_name, created_at, id, is_blue_verified, location, description, parody_commentary_fan_label, verified, entryId, __typename, full_text, id_str, is_quote_status, lang, possibly_sensitive, possibly_sensitive_editable, quote_count, reply_count, retweet_count, retweeted, user_id_str) and an autogenerated `ts` timestamp.

Deduplication & primary key
---------------------------
Extracted tweets are stored using `id_str` as the PRIMARY KEY. Inserts use `INSERT OR IGNORE` so duplicate id_str values are ignored (no duplicate rows). If `id_str` is missing in an extracted object, the addon will skip persisting that item — the addon does not attempt any id fallback or migration.

Indexing
--------
`id_str` is the primary key (and therefore indexed) — use it to look up tweets quickly.
